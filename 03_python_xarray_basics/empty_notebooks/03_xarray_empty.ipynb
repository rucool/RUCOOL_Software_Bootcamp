{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xarray \n",
    "\n",
    "<!-- ![](http://xarray.pydata.org/en/stable/_static/dataset-diagram-logo.png) -->\n",
    "\n",
    "In this lesson we are going to learn about the `Xarray` library - one of the most useful libraries available to us as earth/ocean/atmospheric researchers.\n",
    "\n",
    "### credit \n",
    "\n",
    "This lesson is from the Geohackweek tutorial on Xarray (https://geohackweek.github.io/nDarrays/), and  Abernathy's book: (https://earth-env-data-science.github.io/lectures/xarray/xarray_intro.html). \n",
    "\n",
    "### Think of Xarray as a bit like numpy, except that it has a better 'understanding' of the dimensions of your data.\n",
    "\n",
    "## Multidimensional Arrays \n",
    "(not as scary as they sound)\n",
    "\n",
    "### Like a table in Excel but with more than two dimensions\n",
    "\n",
    "Let's start by drawing some 2D arrays (familiar spreadsheets) on the board. List a bunch of types of data that might fit in that format. \n",
    "\n",
    "Now extend this idea: what are common examples of 3D arrays? What type of ocean/earth/atmos data might fit this format? Can we see how they are easily related to 2D arrays?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Xarray?\n",
    "\n",
    "Xarray is a python library that brings the convienient features of Pandas to higher dimensions. It was initally developed by people at the Climate Corporation for dealing with climate data. It turns out it's very useful in much of our work. \n",
    "\n",
    "Like Pandas, Xarray let's us do operations on named dimensions. It keeps a lot of the 'metadata' associted with the actually data that makes plotting, calculating, and grouping much easier. \n",
    "\n",
    "It also is a great way to load data formats that we will see a lot in our work, in particular NetCDFs (more on this later). \n",
    "\n",
    "\n",
    "features:\n",
    "\n",
    "the `DataArray` is Xarray’s standard data type: a labeled, multi-dimensional array\n",
    "\n",
    "the `DataArray` has these key properties:\n",
    "\n",
    "* `data`: N-dimensional array (NumPy or dask) holding the array’s values, i.e. your actual data,\n",
    "\n",
    "* `dims`: dimension names for each axis, just the names, like 'latitude' or 'longitude' or 'time'\n",
    "\n",
    "* `coords`: dictionary-like container of arrays that label each point, i.e. the actual values of each axis like time or latitue or something\n",
    "\n",
    "* `attrs`: ordered dictionary holding metadata, or 'attributes',  like the data units, person who collected, any of that stuff\n",
    "\n",
    "\n",
    "The second main data structure is the `Dataset` - which you can think of as a group of `DataArray`, like perhaps a grid that has a temperature `DataArray`, a salinity `DataArray`, and an oxygen `DataArray` that are all from the same instument or model and belong together. These can be housed within one `Dataset`. We will show this later\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When to use Xarray?\n",
    "\n",
    "* if your data are multidimensional, like lat, lon, x, y, z, time ...\n",
    "* if your data are on a regular grid (output from a model)\n",
    "* if your data are contained in a `.nc` netcdf file.\n",
    "\n",
    "![](dataset-diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What can Xarray do for *me*?\n",
    "\n",
    "Think about how you would want to build a data structure. Let's go through on the board all the things that should go along with your data. For concretness let's think about the temperature at all depths and points in the mid-Atlantic Bight, from a model say. What do we need to know? We can name all those vectors, but wouldn't it be easier if they all lived with the data itself??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a simple DataArray\n",
    "\n",
    "That is maybe a lot of complex info. Let's start from the basic basics and build up our own `DataArray` using Xarray to see how all it's parts work\n",
    "\n",
    "We will start with some fake data, just a sequence of numbers. Make up something about what they are. \n",
    "\n",
    "We need to download xarray using `conda` like we have before:\n",
    "\n",
    "### installing `xarray` with (Ana)conda (if you don't have it installed already or there was a problem)\n",
    "to get `xarray` (you should only need to do this once):\n",
    "1. go to the little `+` on the left to open a `launcher` window. \n",
    "1. click the 'terminal' tile to open a terminal\n",
    "1. type `conda env list` and hit enter. Make sure that there is a `*` next to the line that says swbc\n",
    "1. if that's right type ` conda install xarray dask netCDF4 bottleneck pandas`\n",
    "1. when it asks `proceed ([y]/n)?` type `y` and hit enter\n",
    "\n",
    "\n",
    "Of course, to start we need to import xarray. To save typing we usualy ask python to call xarray 'xr'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use the `xr.DataArray()` function to make our fake dataarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, that is just some data, a few numbers. So far this isn't anything more special than a numpy array. But it'll get better if we can give it some dimensions and coordinates that give the data context. Maybe those are the number of birds we counted at 10 minute intervals while we were staring out the window in class.\n",
    "\n",
    "Let's add the dimention `time` to the DataArray:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now we know that the data correspond to times, that's good. It's giving us a more complete understanding of the context of the data. But what times? \n",
    "\n",
    "We've named the dimension, but now let's give it some coordinates, in otherwords let's specify the exact times when we measured those birds. \n",
    "\n",
    "In order to connect the dimension to an actual set of time points (i.e. coordinates) we need to recall a Python data type we talked about a while ago. \n",
    "\n",
    "## Quick Aside: Dictionaries  - remember that python data type?\n",
    "Quick summary: A Dictionary is a lot like a list, but it has a label for each element in the list. Namely a Dictionary is made up of key : values pairs. You can think of it literally like a dictonary: you'd look something by it's name (key) and there would be other information in there (the values). We define a ditionary uscing curly brackets: `dict = {}` and we separate keys from their values with a colon `:`\n",
    "\n",
    "\n",
    "``` python\n",
    "d = {\n",
    "    <key>: <value>,\n",
    "    <key>: <value>,\n",
    "      .\n",
    "      .\n",
    "      .\n",
    "    <key>: <value>\n",
    "}\n",
    "```\n",
    "\n",
    "For example we can make a dictionary where the key is a city, and the value is that city's baseball team:\n",
    "\n",
    "``` python\n",
    "MLB_team = {\n",
    "     'Colorado' : 'Rockies',\n",
    "     'Boston'   : 'Red Sox',\n",
    "     'Minnesota': 'Twins',\n",
    "     'Milwaukee': 'Brewers',\n",
    "     'Seattle'  : 'Mariners'\n",
    " }\n",
    "```\n",
    "\n",
    "\n",
    "Dictionaries aren't too complicated, they are just another way of storing data. We will use them a lot with xarrays. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One use case we can talk about now, we have decided the dimension of our DataArray is time, and we can use a dictionary to associate that key (time) with values ( t1, t2, t3, etc).\n",
    "\n",
    "We've named the dimension, but now let's give it some coordinates, in otherwords let's specify the exact times when we measured those birds. Just to be simple we will say starting at 0 minutes we looked out every 10 minutes to count the birds.\n",
    "\n",
    "When we specify the coordinates, we need to tell xarray that we are refering to the `time` dimention, and then tell it what times we want to include:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have something that pretty much fully describes our experiment (almost, what might we be missing? what about attributue? can you think of some examaples?) \n",
    "\n",
    "From here Xarray has all sorts of built in functions that allow you to interact with your data quickly. Because the DataArray has data, dimentions, and coordinates, Xarray can internally understand a lot about the data. \n",
    "\n",
    "One thing we can do is just ask xarray to make a simple plot. This takes almost no code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The end...\n",
    "\n",
    "# Breakout / exercise 01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a mulidimentional DataArray\n",
    "\n",
    "\n",
    "We made up some data in the simple example. Also, did you notice it's just one dimentional? Let's go through the excercise by building some a multidimentional dataset.\n",
    "\n",
    "This is in the next notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exercise 01 - Make your own DataArray\n",
    "\n",
    "For this exercise we are going to steal a fuction from the library `pandas`, even though we didn't learn about it yet. The function is called `date_range` and it creates an array of dates. Look at the code below, can you figure out what it does?\n",
    "\n",
    "**Task**: Make an xarray dataarray of fake data. Make a dim for time, for the coordinates use `two_years` and for the data use `fake_data` defined as:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "two_years = pd.date_range(start='2014-01-01', end='2016-01-01', freq='D')\n",
    "fake_data = np.sin(2 *np.pi *two_years.dayofyear / 365)\n",
    "\n",
    "```\n",
    "\n",
    "Make a default plot of your dataarray and print out the data contents\n",
    "\n",
    "Don't forget to import xarray and numpy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a multidimentional DataArray and Dataset\n",
    "\n",
    "\n",
    "We made up some data in the simple example. Also, did you notice it's just one dimensional? Let's go through the excercise by building a multidimentional dataset.\n",
    "\n",
    "We are going to start with some data that is just a bunch of normal numpy arrays, so we need to load numpy as well as xarray\n",
    "\n",
    "### credit \n",
    "\n",
    "This lesson is from  Abernathy's book: (https://earth-env-data-science.github.io/lectures/xarray/xarray_intro.html). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: ARGO float\n",
    "\n",
    "![](operation_park_profile.jpg)\n",
    "\n",
    "\n",
    "![](statusbig.png)\n",
    "\n",
    "Let's start by loading some real data. This is ARGO float data that contains temperature and salinity data {What is an Argo float? how does it take data?}. Those data are in the form of numpy arrays, or matricies. So, again, rows and columns. Let's draw on the board what the rows and columns are. They have coordinates like time, depth, latitude, longitude. Stuff you would expect to describe data collected in the ocean. \n",
    "\n",
    "Right now, when we load the data, it's going to be a collection of numpy arrays. They are all seperate objects, and what we'd like to do is stitch them together in a sensible way. To this we are going to create a DataArray, then a Dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are in this container because of how they are saved. Let's break each component out into it's own numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember from the previous notebook. \n",
    "\n",
    "The `DataArray` has these key properties:\n",
    "\n",
    "* `data`: N-dimensional array (NumPy or dask) holding the array’s values, i.e. your actual data,\n",
    "\n",
    "* `dims`: dimension names for each axis, just the names, like 'latitude' or 'longitude' or 'time'\n",
    "\n",
    "* `coords`: dictionary-like container of arrays that label each point, i.e. the actual values of each axis like time or latitue or something\n",
    "\n",
    "* `attrs`: ordered dictionary holding metadata, or 'attributes',  like the data units, person who collected, any of that stuff\n",
    "\n",
    "\n",
    "\n",
    "Let's take the salinity `S` and create a DataArray for it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, this is like the 1D fake bird data we made before, but now it's real 2D salinity data from the ocean. \n",
    "\n",
    "Let's see what xarray does if we ask it to make a simple plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! That is sort of amazing. Xarray knew that the salinity data is 2d - so by default it smartly made a pcolor plot (not a line plot or something). It also knew that time is on the x axis, and the 'levels' (depth) are on the y axis because the dimensions match. It also labeled out axis and formatted the dates.\n",
    "\n",
    "But we aren't done with out DataArray yet. Remember the four parts of a DataArray? `data`, `dims`, `coords`, `attrs`. We can add other important information into the `attrs` part of the DataArray. Can you think of some important info?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "\n",
    "xarray datasets can hold multiple DataArrays. This makes particular sense if the data in those multiple DataArrays share dimensions and coordinates. \n",
    "\n",
    "In our ARGO float example, both the Temperature and Salinity share the same dims and cords. So let's put them together into one dataset that holds all out float observational data. \n",
    "\n",
    "The Dataset constructor takes three arguments:\n",
    "\n",
    "* `data_vars` should be a dictionary with each key as the name of the variable and each can be an already constructed DataArray, or a tuple that looks like this `(dims, data[, attrs])`\n",
    "\n",
    "* `coords` should be a dictionary of the same form as data_vars.\n",
    "\n",
    "* `attrs` should be a dictionary.\n",
    "\n",
    "So here is an example for our argo data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's talk through what all those parts are telling us when we print out `argo`. \n",
    "\n",
    "What about the latitude and longitude? Those seem important and we'd like to use them for plotting and analysis later. They should be coordinates right? They should be the same size as one of the existing coordinates, either level or date. what do you think?\n",
    "\n",
    "to add a new coordinate we can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we just did was add a whole new coordinate `lon`. But actually we know that each `lon` point is at a particular `date` location. So actually we can associate `lon` and `date`. To do that we set the dim of out new coord `lon` to be `date`. We can do the same for `lat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with labeled data\n",
    "\n",
    "We've built our nice dataset for the ARGO float. It has Temperature, salinity and pressure data. Those data also have label dimensions / coordinates that include level, date, lat, and lon. \n",
    "\n",
    "Now we are going to start to see some of the power of Xarray and how those labeled dimensions / coordinates let us make our analysis easier\n",
    "\n",
    "## Selecting data (indexing)\n",
    "\n",
    "Let's say we want to look at some subset of the temperature data (just a slice). We can use standard numpy notation to do this by indicating the number of the row and column we are interested in. Let's say we want to look at the second row and all columns ( so this is like a timeseries at a particular level)\n",
    "\n",
    "using standard numpy indexing this would look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what about a particular depth profile? \n",
    "\n",
    "in standard numpy indexing:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That seems easy enough. But let's say you want to look at the temperature profile from a particular day. How are you going to do that? Well, you'd need to use the `date` dimension, look up the date you want, find it's index (meaning the number/position it comes in the list of dates) then put that index into the `argo.temperature[:,1].plot()` line. \n",
    "\n",
    "This isn't impossible. This is the kind of thing you do all the time in matlab. It's annoying and takes a few lines of code. \n",
    "\n",
    "But xarray solves this problem! using the `.sel()` method you can 'select' a part of your data based on the label. \n",
    "\n",
    "Here is how it works. let's get the profile on Oct 22 2012 by selecting based on the dimension `date`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slicing data\n",
    "\n",
    "We can also grab a bunch of days. Grabbing a bunch of consecutive data is typically called 'slicing'. We have to tell xarray that we want a slice of the `date` dimension. Again, this is new syntax, so don't be worried that you don't know it. You'll learn as you go from examples and from reading the documents for different packages.\n",
    "\n",
    "let's get a couple months around our previous profile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use `.sel()` on the whole dataset to, for example, grab all your data from one day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Math\n",
    "\n",
    "we can do any normal math on these DataArrays and Datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can combine DataArrays of the same size to get derived products like buoyancy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can do standard numpy math stuff like means, standard deviations, etc on dimensions.\n",
    "\n",
    "We can average the whole dataset. xarray is smart, and it's going to average each of the data variabiles independantly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot more cool math/analysis functions we can do with xarray. We will see more of them later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The end...\n",
    "\n",
    "# Breakout / exercise 02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise - plotting and stats\n",
    "\n",
    "First load what we need and create a dataset (the code below is exactly what we did in the class, compressed into one cell). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "argo_data = np.load('../data/argo_float_4901412.npz')\n",
    "\n",
    "data_vars = {'salinity':    (('level', 'date'), argo_data[\"S\"]),\n",
    "             'temperature': (('level', 'date'), argo_data[\"T\"]),\n",
    "             'pressure':    (('level', 'date'), argo_data[\"P\"])}\n",
    "\n",
    "# A dictionary of coordinates\n",
    "coords = coords={'level': argo_data[\"levels\"], 'date': argo_data[\"date\"]}\n",
    " \n",
    "argo = xr.Dataset(data_vars, coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the lesson, we took the standard deviation of every variable in a DataSet and plotted them like this:\n",
    "\n",
    "```python\n",
    "argo_std = argo.std(dim='date')\n",
    "\n",
    "argo_std.temperature.plot()\n",
    "```\n",
    "\n",
    "However, in python, functions can sometimes be chained together. For example:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "x = np.random.rand(10, 10)  # Create an array of random numbers\n",
    "x.mean(axis=1).min()  # Compute the mean along one axis, then the minimum. \n",
    "```\n",
    "\n",
    "So do we need to create the variable `argo_std` before plotting? Could we do the standard deviation and plot in one line of code? Have a go... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do you find the maximum standard deviation in salinity? Again, try in one line of code. Does the answer match your expectation from the plot above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Network Common Data Format: netCDF\n",
    "\n",
    "NetCDF is one of the most common ways that geoscience data is distributed. It was developed in the early 1990s specifically to deal with the challenges associated with multidimensional arrays. \n",
    "\n",
    "Much of the climate/earth/ocean/atmosphere data that you can access will be in the form of netCDF files. They typically have the extention`.nc`, so like `ocean_temps.nc`.\n",
    "\n",
    "NetCDF files are machine independant, meaning that macs, PCs, linux machines, you name it, they can all read the files. \n",
    "\n",
    "Also, the netCDF files are self contained - i.e. they carry all the information about the data they contain with them. So they are 'self-describing' like the datasets and dataArrays we have been building. \n",
    "\n",
    "In fact, Xarray is bascially a package devoted to reading, writing, and manipulating netCDFs. This means it's a super easy and useful way to work with geophysical data from nearly anywhere. \n",
    "\n",
    "In this lesson we are going to use Xarray to load some Sea Surface Temperature data from a netCDF file. We will see how easy it is to make calculations and plots of these big data sets using Xarray.\n",
    "\n",
    "### credit \n",
    "\n",
    "This lesson is from  Abernathy's book: (https://earth-env-data-science.github.io/lectures/xarray/xarray_intro.html). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Loading netCDF datasets\n",
    "\n",
    "The primary tool in the Xarray library that we will use with netCDF files is `xr.open_dataset()`. This will read in a netCDF file and create one of our DataArrays. \n",
    "\n",
    "In this example we are going to read in a Sea Surface Temperature dataset created by NOAA that goes back to the 1800's. You can learn more about the data here: https://www.ncdc.noaa.gov/data-access/marineocean-data/extended-reconstructed-sea-surface-temperature-ersst-v5\n",
    "\n",
    "First, let's do our normal import statements that we need to access the libraries in this new notebook:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load in the data using `xr.open_dataset()` and take a look at it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did that work? There is a lot of information there. Let's go through all of it to make sure we understand what our Dataset looks like. \n",
    "\n",
    "Draw on the board and answer the following:\n",
    "* What are the dimensions of the data?\n",
    "* What is the data itself\n",
    "* what do the coordinate of the dimensions look like?\n",
    "* draw a schematic of the data and label all the 'sides'\n",
    "* what is the stuff in the attributes?\n",
    "\n",
    "\n",
    "# plotting netcdf data\n",
    "\n",
    "Next let's make some plots to look at the data. We have lat, lon, Sea Surface Temperature data over a range of times. Maybe let's start with a simple plot of the SST all over the globe on one particular day. What is a good day?\n",
    "\n",
    "*note* if you look at the time dimension, we see that the data is reported in monthly means with dates on the first of the month - let's pick the first day of a month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what if we pick a different day of the month?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got an error because we asked for a specific day that isn't in the dataset. We can get around this sort of thing luckily!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest point indexing, or 'nearest neighbor lookups'\n",
    "\n",
    "In the case above we input an exact date that is avilabile in our data. What if we didn't know all the exact dates? Try putting a random date in to the plot call.  What if we want to get the time closest to some date we care about? Xarray can handle this if we give it an extra arguement using `method='nearest'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so we can pretty easily make a plot of global SST on a single day. That is pretty cool. \n",
    "\n",
    "We can use this dataset to see some amazing things without doing a lot of hard work thanks to the people who developed xarray (and the people who created/collected the data!!!!!).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Let's make a simple plot to see how global average sea surface temperature has changed over time. Do you think we will be able to see a warming signal?\n",
    "\n",
    "To do this we want to use xarray's `.mean()` function. But we need to tell it what kind of mean we want. In other words we need to define the dimensions over which to take the mean. If we are interested in makeing a plot that shows global averaged sea surface temperature over time, what are the dimentions to average over?\n",
    "\n",
    "we are going to do something like: `ds.sst.mean( dim = ('dim1', ...) ).plot()` fill in the blanks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about just plotting the time average map of SST? What dimensions are we going to average over here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the average temperature as a function of latitude? We want to make a line plot that shows how temperature depends on latitude only, how would we do that?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about a timeseries of temperature at a single point? Let's make a plot of the SST at 45 degrees north, and 230 degrees. How do we do that? Recall the `.sel()` method, and it's arguement `nearest`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "that is a mess. Let's adjust the axis so we can see what is happening in that blue mess. Let's pick 20 years of data, from 1980 to 2000 and zoom in. We can do this by setting the range of the x axis. We are going to build up a lot of tricks to make plots look the way we want. This is one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huh. That's cool. What are we seeing here?\n",
    "\n",
    "Let's plot two different Latitudes, one high lat and one on the equator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Groupby\n",
    "Yep, we can do groupby here too.\n",
    "\n",
    "Let's groupby month and apply a mean. This will give us a climatology of SST from the past couple hundered years at every point on the globe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "climatology at a specific point in the North Atlantic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the July minus Jan differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove a time mean\n",
    "\n",
    "Let's look more clearly at the long term SST trend by removing the seasonal climatology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "timeseries of SST anomaly at a certain point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving data to netcdf\n",
    "\n",
    "Suppose we are always working with the mean surface temperature. Here calculating the mean is fast, but suppose it were very slow... It would be useful to save the mean data so we don't have to repeat the calculation.\n",
    "\n",
    "Xarray makes that very easy. In general it works like this: \n",
    "\n",
    "```python\n",
    "name = \"whatever.nc\"\n",
    "some_dataset.to_netcdf(name)\n",
    "```\n",
    "\n",
    "So lets try that for our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The end...\n",
    "\n",
    "# Breakout / exercise 03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 03 - opening an online dataset\n",
    "\n",
    "## NASA ocean color data \n",
    "\n",
    "\n",
    "This problem demonstrates how we can access Ocean Color data from NASA.\n",
    "\n",
    "\n",
    "The main repository for NASAs ocean color data is: https://oceandata.sci.gsfc.nasa.gov/opendap/\n",
    "\n",
    "We will look at data from the MODIS-Aqua (MODIS-A) satellite, and in particular we will look at the level 3 product, which is data that has gone through the highest level of processing and nicely gridded.\n",
    "\n",
    "\n",
    "NASA organizes data by year and year day. You can see this structure by clicking through the OpenDAP server. The file used in this example contains the mapped chlorophyll-a data for July 28 (year day 210), 2019.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use `xr.open_dataset()` to access the data\n",
    "\n",
    "The data for yearday 210 of 2019 is located at:\n",
    "```python\n",
    "# url = 'https://oceandata.sci.gsfc.nasa.gov:443/opendap/MODISA/L3SMI/2019/210/A2019210.L3m_DAY_CHL_chlor_a_4km.nc' -->\n",
    "\n",
    "url = '../../04_cartopy/data/A2019210.L3m_DAY_CHL_chlor_a_4km.nc'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset the data\n",
    "\n",
    "let's just grab the mid-atlantic bight.\n",
    "\n",
    "Note, that for some reason I don't understand, the `lat` `coords` are listed from high to low, so when you slice, you need to reverse the order, i.e. use `sel( lat=slice(41, 38))` *not* `sel( lat=slice( 38, 41)`. This is a mystery.\n",
    "\n",
    "fill in the blanks to get a subset of the data that covers the MAB (the lat boundaries at 38 to 41 degrees, and lon boundaries are -76 to -71):\n",
    "\n",
    "```python\n",
    "data_mab_nj = data.___( lat = ___, lon = ___)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot the chlorophyll a\n",
    "\n",
    "for the mid atlantic bight subset using the built-in xarray plotting routine. i.e. fill in the blanks, and remember we want to just plot the variable `chlor_a`:\n",
    "```python\n",
    "data_mab_nj.___.___()\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chla should be plotted on a log scale\n",
    "\n",
    "Let's make the same plot with matplotlib, and use `np.log10()` to plot the data on a log scale:\n",
    "\n",
    "```python\n",
    "plt.pcolormesh( data_mab_nj.___, data_mab_nj.___, np.log10(data_mab_nj.___))\n",
    "# add a colorbar\n",
    "\n",
    "\n",
    "```\n",
    "be sure to label all your axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
