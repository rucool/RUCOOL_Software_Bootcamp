{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Build a multidimentional DataArray and Dataset\n", "\n", "\n", "We made up some data in the simple example. Also, did you notice it's just one dimensional? Let's go through the excercise by building a multidimentional dataset.\n", "\n", "We are going to start with some data that is just a bunch of normal numpy arrays, so we need to load numpy as well as xarray\n", "\n", "### credit \n", "\n", "This lesson is from  Abernathy's book: (https://earth-env-data-science.github.io/lectures/xarray/xarray_intro.html). \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["# Example: ARGO float\n", "\n", "![](operation_park_profile.jpg)\n", "\n", "\n", "![](statusbig.png)\n", "\n", "Let's start by loading some real data. This is ARGO float data that contains temperature and salinity data {What is an Argo float? how does it take data?}. Those data are in the form of numpy arrays, or matricies. So, again, rows and columns. Let's draw on the board what the rows and columns are. They have coordinates like time, depth, latitude, longitude. Stuff you would expect to describe data collected in the ocean. \n", "\n", "Right now, when we load the data, it's going to be a collection of numpy arrays. They are all seperate objects, and what we'd like to do is stitch them together in a sensible way. To this we are going to create a DataArray, then a Dataset. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["They are in this container because of how they are saved. Let's break each component out into it's own numpy array"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["Remember from the previous notebook. \n", "\n", "The `DataArray` has these key properties:\n", "\n", "* `data`: N-dimensional array (NumPy or dask) holding the array\u2019s values, i.e. your actual data,\n", "\n", "* `dims`: dimension names for each axis, just the names, like 'latitude' or 'longitude' or 'time'\n", "\n", "* `coords`: dictionary-like container of arrays that label each point, i.e. the actual values of each axis like time or latitue or something\n", "\n", "* `attrs`: ordered dictionary holding metadata, or 'attributes',  like the data units, person who collected, any of that stuff\n", "\n", "\n", "\n", "Let's take the salinity `S` and create a DataArray for it"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["Ok, this is like the 1D fake bird data we made before, but now it's real 2D salinity data from the ocean. \n", "\n", "Let's see what xarray does if we ask it to make a simple plot:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["Nice! That is sort of amazing. Xarray knew that the salinity data is 2d - so by default it smartly made a pcolor plot (not a line plot or something). It also knew that time is on the x axis, and the 'levels' (depth) are on the y axis because the dimensions match. It also labeled out axis and formatted the dates.\n", "\n", "But we aren't done with out DataArray yet. Remember the four parts of a DataArray? `data`, `dims`, `coords`, `attrs`. We can add other important information into the `attrs` part of the DataArray. Can you think of some important info?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["# Datasets\n", "\n", "xarray datasets can hold multiple DataArrays. This makes particular sense if the data in those multiple DataArrays share dimensions and coordinates. \n", "\n", "In our ARGO float example, both the Temperature and Salinity share the same dims and cords. So let's put them together into one dataset that holds all out float observational data. \n", "\n", "The Dataset constructor takes three arguments:\n", "\n", "* `data_vars` should be a dictionary with each key as the name of the variable and each can be an already constructed DataArray, or a tuple that looks like this `(dims, data[, attrs])`\n", "\n", "* `coords` should be a dictionary of the same form as data_vars.\n", "\n", "* `attrs` should be a dictionary.\n", "\n", "So here is an example for our argo data:\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's talk through what all those parts are telling us when we print out `argo`. \n", "\n", "What about the latitude and longitude? Those seem important and we'd like to use them for plotting and analysis later. They should be coordinates right? They should be the same size as one of the existing coordinates, either level or date. what do you think?\n", "\n", "to add a new coordinate we can use:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["What we just did was add a whole new coordinate `lon`. But actually we know that each `lon` point is at a particular `date` location. So actually we can associate `lon` and `date`. To do that we set the dim of out new coord `lon` to be `date`. We can do the same for `lat`."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["# Working with labeled data\n", "\n", "We've built our nice dataset for the ARGO float. It has Temperature, salinity and pressure data. Those data also have label dimensions / coordinates that include level, date, lat, and lon. \n", "\n", "Now we are going to start to see some of the power of Xarray and how those labeled dimensions / coordinates let us make our analysis easier\n", "\n", "## Selecting data (indexing)\n", "\n", "Let's say we want to look at some subset of the temperature data (just a slice). We can use standard numpy notation to do this by indicating the number of the row and column we are interested in. Let's say we want to look at the second row and all columns ( so this is like a timeseries at a particular level)\n", "\n", "using standard numpy indexing this would look like:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["what about a particular depth profile? \n", "\n", "in standard numpy indexing:\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["That seems easy enough. But let's say you want to look at the temperature profile from a particular day. How are you going to do that? Well, you'd need to use the `date` dimension, look up the date you want, find it's index (meaning the number/position it comes in the list of dates) then put that index into the `argo.temperature[:,1].plot()` line. \n", "\n", "This isn't impossible. This is the kind of thing you do all the time in matlab. It's annoying and takes a few lines of code. \n", "\n", "But xarray solves this problem! using the `.sel()` method you can 'select' a part of your data based on the label. \n", "\n", "Here is how it works. let's get the profile on Oct 22 2012 by selecting based on the dimension `date`:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["# Slicing data\n", "\n", "We can also grab a bunch of days. Grabbing a bunch of consecutive data is typically called 'slicing'. We have to tell xarray that we want a slice of the `date` dimension. Again, this is new syntax, so don't be worried that you don't know it. You'll learn as you go from examples and from reading the documents for different packages.\n", "\n", "let's get a couple months around our previous profile:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["You can also use `.sel()` on the whole dataset to, for example, grab all your data from one day:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["# Math\n", "\n", "we can do any normal math on these DataArrays and Datasets:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["you can combine DataArrays of the same size to get derived products like buoyancy:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["we can do standard numpy math stuff like means, standard deviations, etc on dimensions.\n", "\n", "We can average the whole dataset. xarray is smart, and it's going to average each of the data variabiles independantly:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["There are a lot more cool math/analysis functions we can do with xarray. We will see more of them later on."]}, {"cell_type": "markdown", "metadata": {}, "source": ["The end...\n", "\n", "# Breakout / exercise 02"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.11"}}, "nbformat": 4, "nbformat_minor": 4}